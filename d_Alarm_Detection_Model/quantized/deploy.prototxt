layer {
  name: "data"
  type: "Input"
  top: "data"
  transform_param {
    scale: 0.00390625
    mirror: false
    yolo_height: 416
    yolo_width: 416
  }
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 416
      dim: 416
    }
  }
}
layer {
  name: "data_fixed"
  type: "FixedNeuron"
  bottom: "data"
  top: "data"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: OVER_FLOW
    bit_width: 8
    follow_data_layer: true
  }
}
layer {
  name: "layer0-conv"
  type: "Convolution"
  bottom: "data"
  top: "layer0-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer0-act"
  type: "ReLU"
  bottom: "layer0-conv"
  top: "layer0-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer0-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer0-conv"
  top: "layer0-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer1-conv"
  type: "Convolution"
  bottom: "layer0-conv"
  top: "layer1-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer1-act"
  type: "ReLU"
  bottom: "layer1-conv"
  top: "layer1-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer1-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer1-conv"
  top: "layer1-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer2-conv"
  type: "Convolution"
  bottom: "layer1-conv"
  top: "layer2-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer2-act"
  type: "ReLU"
  bottom: "layer2-conv"
  top: "layer2-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer4-conv"
  type: "Convolution"
  bottom: "layer1-conv"
  top: "layer4-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer4-act"
  type: "ReLU"
  bottom: "layer4-conv"
  top: "layer4-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer4-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer4-conv"
  top: "layer4-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer5-conv"
  type: "Convolution"
  bottom: "layer4-conv"
  top: "layer5-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer5-act"
  type: "ReLU"
  bottom: "layer5-conv"
  top: "layer5-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer5-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer5-conv"
  top: "layer5-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer6-conv"
  type: "Convolution"
  bottom: "layer5-conv"
  top: "layer6-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer6-act"
  type: "ReLU"
  bottom: "layer6-conv"
  top: "layer6-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer6-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer6-conv"
  top: "layer6-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer7-shortcut"
  type: "Eltwise"
  bottom: "layer4-conv"
  bottom: "layer6-conv"
  top: "layer7-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer7-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer7-shortcut"
  top: "layer7-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer8-conv"
  type: "Convolution"
  bottom: "layer7-shortcut"
  top: "layer8-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer8-act"
  type: "ReLU"
  bottom: "layer8-conv"
  top: "layer8-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer9-concat"
  type: "Concat"
  bottom: "layer8-conv"
  bottom: "layer2-conv"
  top: "layer9-concat"
  phase: TRAIN
}
layer {
  name: "layer9-concat_fixed"
  type: "FixedNeuron"
  bottom: "layer9-concat"
  top: "layer9-concat"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer10-conv"
  type: "Convolution"
  bottom: "layer9-concat"
  top: "layer10-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer10-act"
  type: "ReLU"
  bottom: "layer10-conv"
  top: "layer10-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer10-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer10-conv"
  top: "layer10-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer11-conv"
  type: "Convolution"
  bottom: "layer10-conv"
  top: "layer11-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer11-act"
  type: "ReLU"
  bottom: "layer11-conv"
  top: "layer11-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer11-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer11-conv"
  top: "layer11-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer12-conv"
  type: "Convolution"
  bottom: "layer11-conv"
  top: "layer12-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer12-act"
  type: "ReLU"
  bottom: "layer12-conv"
  top: "layer12-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer14-conv"
  type: "Convolution"
  bottom: "layer11-conv"
  top: "layer14-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer14-act"
  type: "ReLU"
  bottom: "layer14-conv"
  top: "layer14-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer14-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer14-conv"
  top: "layer14-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer15-conv"
  type: "Convolution"
  bottom: "layer14-conv"
  top: "layer15-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer15-act"
  type: "ReLU"
  bottom: "layer15-conv"
  top: "layer15-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer15-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer15-conv"
  top: "layer15-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer16-conv"
  type: "Convolution"
  bottom: "layer15-conv"
  top: "layer16-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer16-act"
  type: "ReLU"
  bottom: "layer16-conv"
  top: "layer16-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer16-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer16-conv"
  top: "layer16-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer17-shortcut"
  type: "Eltwise"
  bottom: "layer14-conv"
  bottom: "layer16-conv"
  top: "layer17-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer17-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer17-shortcut"
  top: "layer17-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer18-conv"
  type: "Convolution"
  bottom: "layer17-shortcut"
  top: "layer18-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer18-act"
  type: "ReLU"
  bottom: "layer18-conv"
  top: "layer18-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer18-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer18-conv"
  top: "layer18-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer19-conv"
  type: "Convolution"
  bottom: "layer18-conv"
  top: "layer19-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer19-act"
  type: "ReLU"
  bottom: "layer19-conv"
  top: "layer19-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer19-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer19-conv"
  top: "layer19-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer20-shortcut"
  type: "Eltwise"
  bottom: "layer17-shortcut"
  bottom: "layer19-conv"
  top: "layer20-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer20-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer20-shortcut"
  top: "layer20-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer21-conv"
  type: "Convolution"
  bottom: "layer20-shortcut"
  top: "layer21-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer21-act"
  type: "ReLU"
  bottom: "layer21-conv"
  top: "layer21-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer22-concat"
  type: "Concat"
  bottom: "layer21-conv"
  bottom: "layer12-conv"
  top: "layer22-concat"
  phase: TRAIN
}
layer {
  name: "layer22-concat_fixed"
  type: "FixedNeuron"
  bottom: "layer22-concat"
  top: "layer22-concat"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer23-conv"
  type: "Convolution"
  bottom: "layer22-concat"
  top: "layer23-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer23-act"
  type: "ReLU"
  bottom: "layer23-conv"
  top: "layer23-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer23-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer23-conv"
  top: "layer23-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer24-conv"
  type: "Convolution"
  bottom: "layer23-conv"
  top: "layer24-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer24-act"
  type: "ReLU"
  bottom: "layer24-conv"
  top: "layer24-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer24-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer24-conv"
  top: "layer24-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer25-conv"
  type: "Convolution"
  bottom: "layer24-conv"
  top: "layer25-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer25-act"
  type: "ReLU"
  bottom: "layer25-conv"
  top: "layer25-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer27-conv"
  type: "Convolution"
  bottom: "layer24-conv"
  top: "layer27-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer27-act"
  type: "ReLU"
  bottom: "layer27-conv"
  top: "layer27-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer27-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer27-conv"
  top: "layer27-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer28-conv"
  type: "Convolution"
  bottom: "layer27-conv"
  top: "layer28-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer28-act"
  type: "ReLU"
  bottom: "layer28-conv"
  top: "layer28-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer28-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer28-conv"
  top: "layer28-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer29-conv"
  type: "Convolution"
  bottom: "layer28-conv"
  top: "layer29-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer29-act"
  type: "ReLU"
  bottom: "layer29-conv"
  top: "layer29-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer29-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer29-conv"
  top: "layer29-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer30-shortcut"
  type: "Eltwise"
  bottom: "layer27-conv"
  bottom: "layer29-conv"
  top: "layer30-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer30-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer30-shortcut"
  top: "layer30-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer31-conv"
  type: "Convolution"
  bottom: "layer30-shortcut"
  top: "layer31-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer31-act"
  type: "ReLU"
  bottom: "layer31-conv"
  top: "layer31-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer31-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer31-conv"
  top: "layer31-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer32-conv"
  type: "Convolution"
  bottom: "layer31-conv"
  top: "layer32-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer32-act"
  type: "ReLU"
  bottom: "layer32-conv"
  top: "layer32-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer32-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer32-conv"
  top: "layer32-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer33-shortcut"
  type: "Eltwise"
  bottom: "layer30-shortcut"
  bottom: "layer32-conv"
  top: "layer33-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer33-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer33-shortcut"
  top: "layer33-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer34-conv"
  type: "Convolution"
  bottom: "layer33-shortcut"
  top: "layer34-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer34-act"
  type: "ReLU"
  bottom: "layer34-conv"
  top: "layer34-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer34-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer34-conv"
  top: "layer34-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer35-conv"
  type: "Convolution"
  bottom: "layer34-conv"
  top: "layer35-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer35-act"
  type: "ReLU"
  bottom: "layer35-conv"
  top: "layer35-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer35-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer35-conv"
  top: "layer35-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer36-shortcut"
  type: "Eltwise"
  bottom: "layer33-shortcut"
  bottom: "layer35-conv"
  top: "layer36-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer36-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer36-shortcut"
  top: "layer36-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer37-conv"
  type: "Convolution"
  bottom: "layer36-shortcut"
  top: "layer37-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer37-act"
  type: "ReLU"
  bottom: "layer37-conv"
  top: "layer37-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer37-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer37-conv"
  top: "layer37-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer38-conv"
  type: "Convolution"
  bottom: "layer37-conv"
  top: "layer38-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer38-act"
  type: "ReLU"
  bottom: "layer38-conv"
  top: "layer38-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer38-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer38-conv"
  top: "layer38-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer39-shortcut"
  type: "Eltwise"
  bottom: "layer36-shortcut"
  bottom: "layer38-conv"
  top: "layer39-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer39-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer39-shortcut"
  top: "layer39-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer40-conv"
  type: "Convolution"
  bottom: "layer39-shortcut"
  top: "layer40-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer40-act"
  type: "ReLU"
  bottom: "layer40-conv"
  top: "layer40-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer40-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer40-conv"
  top: "layer40-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer41-conv"
  type: "Convolution"
  bottom: "layer40-conv"
  top: "layer41-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer41-act"
  type: "ReLU"
  bottom: "layer41-conv"
  top: "layer41-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer41-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer41-conv"
  top: "layer41-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer42-shortcut"
  type: "Eltwise"
  bottom: "layer39-shortcut"
  bottom: "layer41-conv"
  top: "layer42-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer42-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer42-shortcut"
  top: "layer42-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer43-conv"
  type: "Convolution"
  bottom: "layer42-shortcut"
  top: "layer43-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer43-act"
  type: "ReLU"
  bottom: "layer43-conv"
  top: "layer43-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer43-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer43-conv"
  top: "layer43-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer44-conv"
  type: "Convolution"
  bottom: "layer43-conv"
  top: "layer44-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer44-act"
  type: "ReLU"
  bottom: "layer44-conv"
  top: "layer44-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer44-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer44-conv"
  top: "layer44-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer45-shortcut"
  type: "Eltwise"
  bottom: "layer42-shortcut"
  bottom: "layer44-conv"
  top: "layer45-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer45-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer45-shortcut"
  top: "layer45-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer46-conv"
  type: "Convolution"
  bottom: "layer45-shortcut"
  top: "layer46-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer46-act"
  type: "ReLU"
  bottom: "layer46-conv"
  top: "layer46-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer46-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer46-conv"
  top: "layer46-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer47-conv"
  type: "Convolution"
  bottom: "layer46-conv"
  top: "layer47-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer47-act"
  type: "ReLU"
  bottom: "layer47-conv"
  top: "layer47-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer47-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer47-conv"
  top: "layer47-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer48-shortcut"
  type: "Eltwise"
  bottom: "layer45-shortcut"
  bottom: "layer47-conv"
  top: "layer48-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer48-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer48-shortcut"
  top: "layer48-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer49-conv"
  type: "Convolution"
  bottom: "layer48-shortcut"
  top: "layer49-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer49-act"
  type: "ReLU"
  bottom: "layer49-conv"
  top: "layer49-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer49-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer49-conv"
  top: "layer49-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer50-conv"
  type: "Convolution"
  bottom: "layer49-conv"
  top: "layer50-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer50-act"
  type: "ReLU"
  bottom: "layer50-conv"
  top: "layer50-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer50-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer50-conv"
  top: "layer50-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer51-shortcut"
  type: "Eltwise"
  bottom: "layer48-shortcut"
  bottom: "layer50-conv"
  top: "layer51-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer51-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer51-shortcut"
  top: "layer51-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer52-conv"
  type: "Convolution"
  bottom: "layer51-shortcut"
  top: "layer52-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer52-act"
  type: "ReLU"
  bottom: "layer52-conv"
  top: "layer52-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer53-concat"
  type: "Concat"
  bottom: "layer52-conv"
  bottom: "layer25-conv"
  top: "layer53-concat"
  phase: TRAIN
}
layer {
  name: "layer53-concat_fixed"
  type: "FixedNeuron"
  bottom: "layer53-concat"
  top: "layer53-concat"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer54-conv"
  type: "Convolution"
  bottom: "layer53-concat"
  top: "layer54-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer54-act"
  type: "ReLU"
  bottom: "layer54-conv"
  top: "layer54-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer54-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer54-conv"
  top: "layer54-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer55-conv"
  type: "Convolution"
  bottom: "layer54-conv"
  top: "layer55-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer55-act"
  type: "ReLU"
  bottom: "layer55-conv"
  top: "layer55-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer55-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer55-conv"
  top: "layer55-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer56-conv"
  type: "Convolution"
  bottom: "layer55-conv"
  top: "layer56-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer56-act"
  type: "ReLU"
  bottom: "layer56-conv"
  top: "layer56-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer58-conv"
  type: "Convolution"
  bottom: "layer55-conv"
  top: "layer58-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer58-act"
  type: "ReLU"
  bottom: "layer58-conv"
  top: "layer58-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer58-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer58-conv"
  top: "layer58-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer59-conv"
  type: "Convolution"
  bottom: "layer58-conv"
  top: "layer59-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer59-act"
  type: "ReLU"
  bottom: "layer59-conv"
  top: "layer59-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer59-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer59-conv"
  top: "layer59-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer60-conv"
  type: "Convolution"
  bottom: "layer59-conv"
  top: "layer60-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer60-act"
  type: "ReLU"
  bottom: "layer60-conv"
  top: "layer60-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer60-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer60-conv"
  top: "layer60-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer61-shortcut"
  type: "Eltwise"
  bottom: "layer58-conv"
  bottom: "layer60-conv"
  top: "layer61-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer61-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer61-shortcut"
  top: "layer61-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer62-conv"
  type: "Convolution"
  bottom: "layer61-shortcut"
  top: "layer62-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer62-act"
  type: "ReLU"
  bottom: "layer62-conv"
  top: "layer62-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer62-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer62-conv"
  top: "layer62-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer63-conv"
  type: "Convolution"
  bottom: "layer62-conv"
  top: "layer63-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer63-act"
  type: "ReLU"
  bottom: "layer63-conv"
  top: "layer63-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer63-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer63-conv"
  top: "layer63-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer64-shortcut"
  type: "Eltwise"
  bottom: "layer61-shortcut"
  bottom: "layer63-conv"
  top: "layer64-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer64-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer64-shortcut"
  top: "layer64-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer65-conv"
  type: "Convolution"
  bottom: "layer64-shortcut"
  top: "layer65-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer65-act"
  type: "ReLU"
  bottom: "layer65-conv"
  top: "layer65-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer65-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer65-conv"
  top: "layer65-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer66-conv"
  type: "Convolution"
  bottom: "layer65-conv"
  top: "layer66-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer66-act"
  type: "ReLU"
  bottom: "layer66-conv"
  top: "layer66-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer66-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer66-conv"
  top: "layer66-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer67-shortcut"
  type: "Eltwise"
  bottom: "layer64-shortcut"
  bottom: "layer66-conv"
  top: "layer67-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer67-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer67-shortcut"
  top: "layer67-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer68-conv"
  type: "Convolution"
  bottom: "layer67-shortcut"
  top: "layer68-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer68-act"
  type: "ReLU"
  bottom: "layer68-conv"
  top: "layer68-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer68-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer68-conv"
  top: "layer68-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer69-conv"
  type: "Convolution"
  bottom: "layer68-conv"
  top: "layer69-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer69-act"
  type: "ReLU"
  bottom: "layer69-conv"
  top: "layer69-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer69-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer69-conv"
  top: "layer69-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer70-shortcut"
  type: "Eltwise"
  bottom: "layer67-shortcut"
  bottom: "layer69-conv"
  top: "layer70-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer70-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer70-shortcut"
  top: "layer70-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer71-conv"
  type: "Convolution"
  bottom: "layer70-shortcut"
  top: "layer71-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer71-act"
  type: "ReLU"
  bottom: "layer71-conv"
  top: "layer71-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer71-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer71-conv"
  top: "layer71-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer72-conv"
  type: "Convolution"
  bottom: "layer71-conv"
  top: "layer72-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer72-act"
  type: "ReLU"
  bottom: "layer72-conv"
  top: "layer72-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer72-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer72-conv"
  top: "layer72-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer73-shortcut"
  type: "Eltwise"
  bottom: "layer70-shortcut"
  bottom: "layer72-conv"
  top: "layer73-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer73-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer73-shortcut"
  top: "layer73-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer74-conv"
  type: "Convolution"
  bottom: "layer73-shortcut"
  top: "layer74-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer74-act"
  type: "ReLU"
  bottom: "layer74-conv"
  top: "layer74-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer74-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer74-conv"
  top: "layer74-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer75-conv"
  type: "Convolution"
  bottom: "layer74-conv"
  top: "layer75-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer75-act"
  type: "ReLU"
  bottom: "layer75-conv"
  top: "layer75-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer75-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer75-conv"
  top: "layer75-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer76-shortcut"
  type: "Eltwise"
  bottom: "layer73-shortcut"
  bottom: "layer75-conv"
  top: "layer76-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer76-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer76-shortcut"
  top: "layer76-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer77-conv"
  type: "Convolution"
  bottom: "layer76-shortcut"
  top: "layer77-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer77-act"
  type: "ReLU"
  bottom: "layer77-conv"
  top: "layer77-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer77-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer77-conv"
  top: "layer77-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer78-conv"
  type: "Convolution"
  bottom: "layer77-conv"
  top: "layer78-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer78-act"
  type: "ReLU"
  bottom: "layer78-conv"
  top: "layer78-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer78-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer78-conv"
  top: "layer78-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer79-shortcut"
  type: "Eltwise"
  bottom: "layer76-shortcut"
  bottom: "layer78-conv"
  top: "layer79-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer79-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer79-shortcut"
  top: "layer79-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer80-conv"
  type: "Convolution"
  bottom: "layer79-shortcut"
  top: "layer80-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer80-act"
  type: "ReLU"
  bottom: "layer80-conv"
  top: "layer80-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer80-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer80-conv"
  top: "layer80-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer81-conv"
  type: "Convolution"
  bottom: "layer80-conv"
  top: "layer81-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer81-act"
  type: "ReLU"
  bottom: "layer81-conv"
  top: "layer81-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer81-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer81-conv"
  top: "layer81-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer82-shortcut"
  type: "Eltwise"
  bottom: "layer79-shortcut"
  bottom: "layer81-conv"
  top: "layer82-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer82-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer82-shortcut"
  top: "layer82-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer83-conv"
  type: "Convolution"
  bottom: "layer82-shortcut"
  top: "layer83-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer83-act"
  type: "ReLU"
  bottom: "layer83-conv"
  top: "layer83-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer84-concat"
  type: "Concat"
  bottom: "layer83-conv"
  bottom: "layer56-conv"
  top: "layer84-concat"
  phase: TRAIN
}
layer {
  name: "layer84-concat_fixed"
  type: "FixedNeuron"
  bottom: "layer84-concat"
  top: "layer84-concat"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer85-conv"
  type: "Convolution"
  bottom: "layer84-concat"
  top: "layer85-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer85-act"
  type: "ReLU"
  bottom: "layer85-conv"
  top: "layer85-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer85-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer85-conv"
  top: "layer85-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer86-conv"
  type: "Convolution"
  bottom: "layer85-conv"
  top: "layer86-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer86-act"
  type: "ReLU"
  bottom: "layer86-conv"
  top: "layer86-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer86-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer86-conv"
  top: "layer86-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer87-conv"
  type: "Convolution"
  bottom: "layer86-conv"
  top: "layer87-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer87-act"
  type: "ReLU"
  bottom: "layer87-conv"
  top: "layer87-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer89-conv"
  type: "Convolution"
  bottom: "layer86-conv"
  top: "layer89-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer89-act"
  type: "ReLU"
  bottom: "layer89-conv"
  top: "layer89-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer89-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer89-conv"
  top: "layer89-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer90-conv"
  type: "Convolution"
  bottom: "layer89-conv"
  top: "layer90-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer90-act"
  type: "ReLU"
  bottom: "layer90-conv"
  top: "layer90-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer90-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer90-conv"
  top: "layer90-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer91-conv"
  type: "Convolution"
  bottom: "layer90-conv"
  top: "layer91-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer91-act"
  type: "ReLU"
  bottom: "layer91-conv"
  top: "layer91-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer91-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer91-conv"
  top: "layer91-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer92-shortcut"
  type: "Eltwise"
  bottom: "layer89-conv"
  bottom: "layer91-conv"
  top: "layer92-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer92-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer92-shortcut"
  top: "layer92-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer93-conv"
  type: "Convolution"
  bottom: "layer92-shortcut"
  top: "layer93-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer93-act"
  type: "ReLU"
  bottom: "layer93-conv"
  top: "layer93-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer93-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer93-conv"
  top: "layer93-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer94-conv"
  type: "Convolution"
  bottom: "layer93-conv"
  top: "layer94-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer94-act"
  type: "ReLU"
  bottom: "layer94-conv"
  top: "layer94-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer94-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer94-conv"
  top: "layer94-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer95-shortcut"
  type: "Eltwise"
  bottom: "layer92-shortcut"
  bottom: "layer94-conv"
  top: "layer95-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer95-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer95-shortcut"
  top: "layer95-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer96-conv"
  type: "Convolution"
  bottom: "layer95-shortcut"
  top: "layer96-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer96-act"
  type: "ReLU"
  bottom: "layer96-conv"
  top: "layer96-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer96-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer96-conv"
  top: "layer96-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer97-conv"
  type: "Convolution"
  bottom: "layer96-conv"
  top: "layer97-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer97-act"
  type: "ReLU"
  bottom: "layer97-conv"
  top: "layer97-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer97-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer97-conv"
  top: "layer97-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer98-shortcut"
  type: "Eltwise"
  bottom: "layer95-shortcut"
  bottom: "layer97-conv"
  top: "layer98-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer98-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer98-shortcut"
  top: "layer98-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer99-conv"
  type: "Convolution"
  bottom: "layer98-shortcut"
  top: "layer99-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer99-act"
  type: "ReLU"
  bottom: "layer99-conv"
  top: "layer99-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer99-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer99-conv"
  top: "layer99-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer100-conv"
  type: "Convolution"
  bottom: "layer99-conv"
  top: "layer100-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer100-act"
  type: "ReLU"
  bottom: "layer100-conv"
  top: "layer100-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer100-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer100-conv"
  top: "layer100-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer101-shortcut"
  type: "Eltwise"
  bottom: "layer98-shortcut"
  bottom: "layer100-conv"
  top: "layer101-shortcut"
  phase: TRAIN
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "layer101-shortcut_fixed"
  type: "FixedNeuron"
  bottom: "layer101-shortcut"
  top: "layer101-shortcut"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer102-conv"
  type: "Convolution"
  bottom: "layer101-shortcut"
  top: "layer102-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer102-act"
  type: "ReLU"
  bottom: "layer102-conv"
  top: "layer102-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer103-concat"
  type: "Concat"
  bottom: "layer102-conv"
  bottom: "layer87-conv"
  top: "layer103-concat"
  phase: TRAIN
}
layer {
  name: "layer103-concat_fixed"
  type: "FixedNeuron"
  bottom: "layer103-concat"
  top: "layer103-concat"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer104-conv"
  type: "Convolution"
  bottom: "layer103-concat"
  top: "layer104-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer104-act"
  type: "ReLU"
  bottom: "layer104-conv"
  top: "layer104-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer104-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer104-conv"
  top: "layer104-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer105-conv"
  type: "Convolution"
  bottom: "layer104-conv"
  top: "layer105-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer105-act"
  type: "ReLU"
  bottom: "layer105-conv"
  top: "layer105-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer105-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer105-conv"
  top: "layer105-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer106-conv"
  type: "Convolution"
  bottom: "layer105-conv"
  top: "layer106-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer106-act"
  type: "ReLU"
  bottom: "layer106-conv"
  top: "layer106-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer106-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer106-conv"
  top: "layer106-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer107-conv"
  type: "Convolution"
  bottom: "layer106-conv"
  top: "layer107-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer107-act"
  type: "ReLU"
  bottom: "layer107-conv"
  top: "layer107-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer107-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer107-conv"
  top: "layer107-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer108-maxpool"
  type: "Pooling"
  bottom: "layer107-conv"
  top: "layer108-maxpool"
  phase: TRAIN
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "layer110-maxpool"
  type: "Pooling"
  bottom: "layer107-conv"
  top: "layer110-maxpool"
  phase: TRAIN
  pooling_param {
    pool: MAX
    kernel_size: 5
    stride: 1
    pad: 2
  }
}
layer {
  name: "layer112-maxpool"
  type: "Pooling"
  bottom: "layer107-conv"
  top: "layer112-maxpool"
  phase: TRAIN
  pooling_param {
    pool: MAX
    kernel_size: 7
    stride: 1
    pad: 3
  }
}
layer {
  name: "layer113-concat"
  type: "Concat"
  bottom: "layer112-maxpool"
  bottom: "layer110-maxpool"
  bottom: "layer108-maxpool"
  bottom: "layer107-conv"
  top: "layer113-concat"
  phase: TRAIN
}
layer {
  name: "layer113-concat_fixed"
  type: "FixedNeuron"
  bottom: "layer113-concat"
  top: "layer113-concat"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer114-conv"
  type: "Convolution"
  bottom: "layer113-concat"
  top: "layer114-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer114-act"
  type: "ReLU"
  bottom: "layer114-conv"
  top: "layer114-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer114-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer114-conv"
  top: "layer114-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer115-conv"
  type: "Convolution"
  bottom: "layer114-conv"
  top: "layer115-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer115-act"
  type: "ReLU"
  bottom: "layer115-conv"
  top: "layer115-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer115-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer115-conv"
  top: "layer115-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer116-conv"
  type: "Convolution"
  bottom: "layer115-conv"
  top: "layer116-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer116-act"
  type: "ReLU"
  bottom: "layer116-conv"
  top: "layer116-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer116-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer116-conv"
  top: "layer116-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer117-conv"
  type: "Convolution"
  bottom: "layer116-conv"
  top: "layer117-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer117-act"
  type: "ReLU"
  bottom: "layer117-conv"
  top: "layer117-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer117-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer117-conv"
  top: "layer117-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer118-upsample"
  type: "DeephiResize"
  bottom: "layer117-conv"
  top: "layer118-upsample"
  phase: TRAIN
  deephi_resize_param {
    scale_h: 2
    scale_w: 2
  }
}
layer {
  name: "layer120-conv"
  type: "Convolution"
  bottom: "layer85-conv"
  top: "layer120-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer120-act"
  type: "ReLU"
  bottom: "layer120-conv"
  top: "layer120-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer121-concat"
  type: "Concat"
  bottom: "layer120-conv"
  bottom: "layer118-upsample"
  top: "layer121-concat"
  phase: TRAIN
}
layer {
  name: "layer121-concat_fixed"
  type: "FixedNeuron"
  bottom: "layer121-concat"
  top: "layer121-concat"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer122-conv"
  type: "Convolution"
  bottom: "layer121-concat"
  top: "layer122-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer122-act"
  type: "ReLU"
  bottom: "layer122-conv"
  top: "layer122-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer122-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer122-conv"
  top: "layer122-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer123-conv"
  type: "Convolution"
  bottom: "layer122-conv"
  top: "layer123-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer123-act"
  type: "ReLU"
  bottom: "layer123-conv"
  top: "layer123-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer123-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer123-conv"
  top: "layer123-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer124-conv"
  type: "Convolution"
  bottom: "layer123-conv"
  top: "layer124-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer124-act"
  type: "ReLU"
  bottom: "layer124-conv"
  top: "layer124-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer124-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer124-conv"
  top: "layer124-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer125-conv"
  type: "Convolution"
  bottom: "layer124-conv"
  top: "layer125-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer125-act"
  type: "ReLU"
  bottom: "layer125-conv"
  top: "layer125-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer125-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer125-conv"
  top: "layer125-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer126-conv"
  type: "Convolution"
  bottom: "layer125-conv"
  top: "layer126-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer126-act"
  type: "ReLU"
  bottom: "layer126-conv"
  top: "layer126-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer126-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer126-conv"
  top: "layer126-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer127-conv"
  type: "Convolution"
  bottom: "layer126-conv"
  top: "layer127-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer127-act"
  type: "ReLU"
  bottom: "layer127-conv"
  top: "layer127-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer127-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer127-conv"
  top: "layer127-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer128-upsample"
  type: "DeephiResize"
  bottom: "layer127-conv"
  top: "layer128-upsample"
  phase: TRAIN
  deephi_resize_param {
    scale_h: 2
    scale_w: 2
  }
}
layer {
  name: "layer130-conv"
  type: "Convolution"
  bottom: "layer54-conv"
  top: "layer130-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer130-act"
  type: "ReLU"
  bottom: "layer130-conv"
  top: "layer130-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer131-concat"
  type: "Concat"
  bottom: "layer130-conv"
  bottom: "layer128-upsample"
  top: "layer131-concat"
  phase: TRAIN
}
layer {
  name: "layer131-concat_fixed"
  type: "FixedNeuron"
  bottom: "layer131-concat"
  top: "layer131-concat"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer132-conv"
  type: "Convolution"
  bottom: "layer131-concat"
  top: "layer132-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer132-act"
  type: "ReLU"
  bottom: "layer132-conv"
  top: "layer132-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer132-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer132-conv"
  top: "layer132-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer133-conv"
  type: "Convolution"
  bottom: "layer132-conv"
  top: "layer133-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer133-act"
  type: "ReLU"
  bottom: "layer133-conv"
  top: "layer133-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer133-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer133-conv"
  top: "layer133-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer134-conv"
  type: "Convolution"
  bottom: "layer133-conv"
  top: "layer134-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer134-act"
  type: "ReLU"
  bottom: "layer134-conv"
  top: "layer134-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer134-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer134-conv"
  top: "layer134-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer135-conv"
  type: "Convolution"
  bottom: "layer134-conv"
  top: "layer135-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer135-act"
  type: "ReLU"
  bottom: "layer135-conv"
  top: "layer135-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer135-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer135-conv"
  top: "layer135-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer136-conv"
  type: "Convolution"
  bottom: "layer135-conv"
  top: "layer136-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer136-act"
  type: "ReLU"
  bottom: "layer136-conv"
  top: "layer136-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer136-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer136-conv"
  top: "layer136-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer137-conv"
  type: "Convolution"
  bottom: "layer136-conv"
  top: "layer137-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer137-act"
  type: "ReLU"
  bottom: "layer137-conv"
  top: "layer137-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer137-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer137-conv"
  top: "layer137-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer138-conv"
  type: "Convolution"
  bottom: "layer137-conv"
  top: "layer138-conv"
  phase: TRAIN
  convolution_param {
    num_output: 255
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer138-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer138-conv"
  top: "layer138-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S_SIGMOID
    bit_width: 8
  }
}
layer {
  name: "layer141-conv"
  type: "Convolution"
  bottom: "layer136-conv"
  top: "layer141-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer141-act"
  type: "ReLU"
  bottom: "layer141-conv"
  top: "layer141-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer142-concat"
  type: "Concat"
  bottom: "layer141-conv"
  bottom: "layer126-conv"
  top: "layer142-concat"
  phase: TRAIN
}
layer {
  name: "layer142-concat_fixed"
  type: "FixedNeuron"
  bottom: "layer142-concat"
  top: "layer142-concat"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer143-conv"
  type: "Convolution"
  bottom: "layer142-concat"
  top: "layer143-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer143-act"
  type: "ReLU"
  bottom: "layer143-conv"
  top: "layer143-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer143-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer143-conv"
  top: "layer143-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer144-conv"
  type: "Convolution"
  bottom: "layer143-conv"
  top: "layer144-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer144-act"
  type: "ReLU"
  bottom: "layer144-conv"
  top: "layer144-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer144-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer144-conv"
  top: "layer144-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer145-conv"
  type: "Convolution"
  bottom: "layer144-conv"
  top: "layer145-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer145-act"
  type: "ReLU"
  bottom: "layer145-conv"
  top: "layer145-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer145-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer145-conv"
  top: "layer145-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer146-conv"
  type: "Convolution"
  bottom: "layer145-conv"
  top: "layer146-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer146-act"
  type: "ReLU"
  bottom: "layer146-conv"
  top: "layer146-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer146-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer146-conv"
  top: "layer146-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer147-conv"
  type: "Convolution"
  bottom: "layer146-conv"
  top: "layer147-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer147-act"
  type: "ReLU"
  bottom: "layer147-conv"
  top: "layer147-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer147-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer147-conv"
  top: "layer147-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer148-conv"
  type: "Convolution"
  bottom: "layer147-conv"
  top: "layer148-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer148-act"
  type: "ReLU"
  bottom: "layer148-conv"
  top: "layer148-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer148-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer148-conv"
  top: "layer148-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer149-conv"
  type: "Convolution"
  bottom: "layer148-conv"
  top: "layer149-conv"
  phase: TRAIN
  convolution_param {
    num_output: 255
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer149-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer149-conv"
  top: "layer149-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S_SIGMOID
    bit_width: 8
  }
}
layer {
  name: "layer152-conv"
  type: "Convolution"
  bottom: "layer147-conv"
  top: "layer152-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer152-act"
  type: "ReLU"
  bottom: "layer152-conv"
  top: "layer152-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer153-concat"
  type: "Concat"
  bottom: "layer152-conv"
  bottom: "layer116-conv"
  top: "layer153-concat"
  phase: TRAIN
}
layer {
  name: "layer153-concat_fixed"
  type: "FixedNeuron"
  bottom: "layer153-concat"
  top: "layer153-concat"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer154-conv"
  type: "Convolution"
  bottom: "layer153-concat"
  top: "layer154-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer154-act"
  type: "ReLU"
  bottom: "layer154-conv"
  top: "layer154-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer154-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer154-conv"
  top: "layer154-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer155-conv"
  type: "Convolution"
  bottom: "layer154-conv"
  top: "layer155-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer155-act"
  type: "ReLU"
  bottom: "layer155-conv"
  top: "layer155-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer155-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer155-conv"
  top: "layer155-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer156-conv"
  type: "Convolution"
  bottom: "layer155-conv"
  top: "layer156-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer156-act"
  type: "ReLU"
  bottom: "layer156-conv"
  top: "layer156-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer156-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer156-conv"
  top: "layer156-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer157-conv"
  type: "Convolution"
  bottom: "layer156-conv"
  top: "layer157-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer157-act"
  type: "ReLU"
  bottom: "layer157-conv"
  top: "layer157-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer157-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer157-conv"
  top: "layer157-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer158-conv"
  type: "Convolution"
  bottom: "layer157-conv"
  top: "layer158-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer158-act"
  type: "ReLU"
  bottom: "layer158-conv"
  top: "layer158-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer158-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer158-conv"
  top: "layer158-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer159-conv"
  type: "Convolution"
  bottom: "layer158-conv"
  top: "layer159-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 0
  }
  phase: TRAIN
  convolution_param {
    num_output: 1024
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "layer159-act"
  type: "ReLU"
  bottom: "layer159-conv"
  top: "layer159-conv"
  phase: TRAIN
  relu_param {
    negative_slope: 0.1015625
  }
}
layer {
  name: "layer159-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer159-conv"
  top: "layer159-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S
    bit_width: 8
  }
}
layer {
  name: "layer160-conv"
  type: "Convolution"
  bottom: "layer159-conv"
  top: "layer160-conv"
  phase: TRAIN
  convolution_param {
    num_output: 255
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "layer160-conv_fixed"
  type: "FixedNeuron"
  bottom: "layer160-conv"
  top: "layer160-conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  phase: TRAIN
  fixed_param {
    fixed_method: DIFF_S_SIGMOID
    bit_width: 8
  }
}
